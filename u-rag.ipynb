{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -qU langchain langchain-community langchain-core langchain-google-genai langsmith youtube-transcript-api langgraph\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langsmith import traceable\n",
    "from langgraph.graph import StateGraph, START\n",
    "from typing_extensions import TypedDict, List\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"****\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"***\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Load YouTube transcript https://www.youtube.com/watch?v=pp59n0So-XE\n",
    "video_id = \"pp59n0So-XE\"  # Replace with your video ID\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "text = \"\\n\".join([entry[\"text\"] for entry in transcript])\n",
    "doc = Document(page_content=text)\n",
    "\n",
    "# Step 2: Chunk transcript\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents([doc])\n",
    "\n",
    "# Step 3: Embed and store\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "_ = vectorstore.add_documents(chunks)\n",
    "\n",
    "# Step 4: Define state\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Step 5: Retrieval\n",
    "def retrieve(state: State):\n",
    "    docs = vectorstore.similarity_search(state[\"question\"])\n",
    "    return {\"context\": docs}\n",
    "\n",
    "# Step 6: Generation\n",
    "@traceable(name=\"generate_answer\")\n",
    "def generate(state: State):\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = [\n",
    "        (\"system\", \"You are a helpful assistant that answers questions based on YouTube transcripts.\"),\n",
    "        (\"human\", f\"Context:\\n{context}\\n\\nQuestion: {state['question']}\")\n",
    "    ]\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Step 7: Build graph\n",
    "graph = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph.add_edge(START, \"retrieve\")\n",
    "app = graph.compile()\n",
    "\n",
    "# Step 8: Run\n",
    "response = app.invoke({\"question\": \"what was jealous?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
